import requests
from bs4 import BeautifulSoup
import time

KEYWORD = "Trump"
SUBREDDIT = "japan"
BASE_URL = f"https://old.reddit.com/r/{SUBREDDIT}/search"
HEADERS = {"User-Agent": "Mozilla/5.0"}

# クエリパラメータを設定
params = {
    "q": KEYWORD,
    "restrict_sr": 1,
    "sort": "new",
    "t": "all"
}

threads = []
after = None
page_count = 0
MAX_PAGES = 5  # 取得するページ数を調整

while page_count < MAX_PAGES:
    if after:
        params["after"] = after
    response = requests.get(BASE_URL, params=params, headers=HEADERS)
    soup = BeautifulSoup(response.text, "html.parser")
    posts = soup.find_all("div", class_="search-result")
    for post in posts:
        title_tag = post.find("a", class_="search-title")
        if not title_tag:
            continue
        title = title_tag.text
        if KEYWORD.lower() in title.lower():
            url = title_tag["href"]
            # 本文取得（スレッドのリンク先をさらにリクエスト）
            post_resp = requests.get(url, headers=HEADERS)
            post_soup = BeautifulSoup(post_resp.text, "html.parser")
            selftext_tag = post_soup.find("div", class_="usertext-body")
            selftext = selftext_tag.text.strip() if selftext_tag else ""
            threads.append({
                "title": title,
                "url": url,
                "selftext": selftext
            })
            time.sleep(1)  # 負荷軽減のため待機
    # 次のページへのリンクを取得
    next_button = soup.find("span", class_="next-button")
    if next_button:
        after = next_button.a["href"].split("after=")[-1]
        page_count += 1
        time.sleep(2)  # 負荷軽減
    else:
        break

# 結果表示
for i, thread in enumerate(threads, 1):
    print(f"--- Thread {i} ---")
    print("Title:", thread['title'])
    print("URL:", thread['url'])
    print("Body:")
    print(thread['selftext'])
    print("\n")
